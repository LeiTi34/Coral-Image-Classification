{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install numpy pillow scikit-learn seaborn tensorflow\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Dataset Overview\n",
    "bleached_path = \"UW-Madison-GI-Tract-Image-Segmentation/data/bleached_corals\"\n",
    "healthy_path = \"UW-Madison-GI-Tract-Image-Segmentation/data/healthy_corals\"\n",
    "\n",
    "def get_image_paths(folder_path):\n",
    "    return [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "\n",
    "# Get all image paths\n",
    "bleached_image_paths = get_image_paths(bleached_path)\n",
    "print(f\"Bleached Corals - Total Images: {len(bleached_image_paths)}\")\n",
    "healthy_image_paths = get_image_paths(healthy_path)\n",
    "print(f\"Healthy Corals - Total Images: {len(healthy_image_paths)}\")\n",
    "\n",
    "# Prepare dataset\n",
    "image_paths = bleached_image_paths + healthy_image_paths\n",
    "labels = ['bleached'] * len(bleached_image_paths) + ['healthy'] * len(healthy_image_paths)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Image Data Generator with Augmentation\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((299, 299))\n",
    "    img = np.array(img)\n",
    "    if img.shape[2] == 4:  # Remove alpha channel if present\n",
    "        img = img[:, :, :3]\n",
    "    return img\n",
    "\n",
    "train_images = np.array([preprocess_image(path) for path in train_paths])\n",
    "test_images = np.array([preprocess_image(path) for path in test_paths])\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load GoogleNet (InceptionV3) model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=32),\n",
    "    epochs=80,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training the model\n",
    "history_fine = model.fit(\n",
    "    datagen.flow(train_images, train_labels, batch_size=32),\n",
    "    epochs=80,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_labels, predicted_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'] + history_fine.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
