{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667e1bc11fdade31",
   "metadata": {},
   "source": [
    "# Image Classification using VGG16_BN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T20:49:47.706723Z",
     "start_time": "2024-12-10T20:49:45.112796Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.5.2)\n",
      "Collecting cnn_finetune\n",
      "  Downloading cnn_finetune-0.6.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting pretrainedmodels>=0.7.4 (from cnn_finetune)\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from cnn_finetune) (4.67.0)\n",
      "Collecting munch (from pretrainedmodels>=0.7.4->cnn_finetune)\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Building wheels for collected packages: cnn_finetune, pretrainedmodels\n",
      "  Building wheel for cnn_finetune (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cnn_finetune: filename=cnn_finetune-0.6.0-py3-none-any.whl size=11428 sha256=7c883043de2c19677d12bb6b425242a6e5b418c92fd5bd7e40c8298d2c88cd33\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/45/5b/32/b1f9eec9048e6c4adbf52ee2dadf13b126ee433baa4ee6fcd5\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=9792a3a6689c64e89522519f47550555e3aec6e361c6a44e96fd0e107d90ede3\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/4c/01/56/40a48f75dbdfe167a0cb70d3b48913369a00ec5c4e9fed5f2b\n",
      "Successfully built cnn_finetune pretrainedmodels\n",
      "Installing collected packages: munch, pretrainedmodels, cnn_finetune\n",
      "Successfully installed cnn_finetune-0.6.0 munch-4.0.0 pretrainedmodels-0.7.4\n"
     ]
    }
   ],
   "source": [
    "# install dependencies and packages\n",
    "!pip install torch torchvision scikit-learn cnn_finetune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dfa503dd2c2bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T20:49:47.725364Z",
     "start_time": "2024-12-10T20:49:47.720763Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# cnn_finetune imports caused problems, using torchvision directly instead\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f79ace37c4b1e6",
   "metadata": {},
   "source": [
    "A custom Dataset class is created to load the coral images from the file paths HEALTHY_IMAGES_DIR and BLEACHED_IMAGES_DIR.\n",
    "The subfolders contain images of healthy and bleached corals.\n",
    "\n",
    "The dataset used is from Kaggle: https://www.kaggle.com/datasets/vencerlanz09/healthy-and-bleached-corals-image-classification/data\n",
    "\n",
    "Dataset Details:\n",
    "+ Total images: 923\n",
    "+ Image categories: 2\n",
    "    + Healthy corals: 438 images\n",
    "    + Bleached corals: 485 images\n",
    "+ Image format: JPEG\n",
    "+ Image size: Maximum 300 px for either width or height, whichever is higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c993edb79af1c626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T20:49:47.771935Z",
     "start_time": "2024-12-10T20:49:47.740089Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare coral dataset\n",
    "\n",
    "class CoralDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "HEALTHY_IMAGES_DIR = \"/data/healthy_corals\"\n",
    "BLEACHED_IMAGES_DIR = \"/data/bleached_corals\"\n",
    "\n",
    "# imagepaths and labels\n",
    "healthy_image_paths = [os.path.join(HEALTHY_IMAGES_DIR, img) for img in os.listdir(HEALTHY_IMAGES_DIR) if os.path.isfile(os.path.join(HEALTHY_IMAGES_DIR, img))]\n",
    "bleached_image_paths = [os.path.join(BLEACHED_IMAGES_DIR, img) for img in os.listdir(BLEACHED_IMAGES_DIR) if os.path.isfile(os.path.join(BLEACHED_IMAGES_DIR, img))]\n",
    "\n",
    "image_paths = healthy_image_paths + bleached_image_paths\n",
    "labels = [0] * len(healthy_image_paths) + [1] * len(bleached_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84316e336162487b",
   "metadata": {},
   "source": [
    "The datasets is splitted into training (80%), validation (10%) and testing (10%).\n",
    "Training data is used for model learning, the validation data evaluates the performance during training and the data assesses the final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a5cddceef2d8f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T20:49:47.792523Z",
     "start_time": "2024-12-10T20:49:47.785072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was successfully split into training, validation, and testing sets\n"
     ]
    }
   ],
   "source": [
    "# split dataset into training (80%), validation (10%) and testing (10%)\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(temp_paths, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print('Dataset was successfully split into training, validation, and testing sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c70d88ddafee0c",
   "metadata": {},
   "source": [
    "For the Loss Function ```nn.CrossEntropyLoss``` because it is suitable for multi-class classification problems \n",
    "\n",
    "For the Optimizer Adam is chosen. Other optimizers like SGD can be used aswell to evaluate the performance.\n",
    "\n",
    "A scheduler is used to adjust the learning rate dynamically during training to optimize the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8436ae1e4d138b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:34:17.199474Z",
     "start_time": "2024-12-10T20:49:47.822764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
      "100%|██████████| 528M/528M [00:05<00:00, 111MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Running Configuration 1 ###\n",
      "\n",
      "Epoch [1/30], Loss: 0.7829, Val Loss: 5.8529, Val Accuracy: 58.70%\n",
      "Epoch [2/30], Loss: 0.6240, Val Loss: 2.8528, Val Accuracy: 69.57%\n",
      "Epoch [3/30], Loss: 0.5673, Val Loss: 0.6746, Val Accuracy: 64.13%\n",
      "Epoch [4/30], Loss: 0.5842, Val Loss: 0.6938, Val Accuracy: 68.48%\n",
      "Epoch [5/30], Loss: 0.6154, Val Loss: 0.7574, Val Accuracy: 71.74%\n",
      "Epoch [6/30], Loss: 0.5800, Val Loss: 0.7524, Val Accuracy: 70.65%\n",
      "Epoch [7/30], Loss: 0.5706, Val Loss: 0.5454, Val Accuracy: 68.48%\n",
      "Epoch [8/30], Loss: 0.4981, Val Loss: 0.5772, Val Accuracy: 76.09%\n",
      "Epoch [9/30], Loss: 0.4881, Val Loss: 0.5371, Val Accuracy: 69.57%\n",
      "Epoch [10/30], Loss: 0.4329, Val Loss: 0.5097, Val Accuracy: 75.00%\n",
      "Epoch [11/30], Loss: 0.4649, Val Loss: 0.5496, Val Accuracy: 70.65%\n",
      "Epoch [12/30], Loss: 0.4523, Val Loss: 0.6544, Val Accuracy: 71.74%\n",
      "Epoch [13/30], Loss: 0.4353, Val Loss: 0.4781, Val Accuracy: 72.83%\n",
      "Epoch [14/30], Loss: 0.4837, Val Loss: 0.9177, Val Accuracy: 69.57%\n",
      "Epoch [15/30], Loss: 0.5169, Val Loss: 1.0132, Val Accuracy: 72.83%\n",
      "Epoch [16/30], Loss: 0.5991, Val Loss: 0.9036, Val Accuracy: 66.30%\n",
      "Epoch [17/30], Loss: 0.4339, Val Loss: 0.5521, Val Accuracy: 78.26%\n",
      "Epoch [18/30], Loss: 0.4248, Val Loss: 0.6056, Val Accuracy: 73.91%\n",
      "Epoch [19/30], Loss: 0.6258, Val Loss: 0.5934, Val Accuracy: 71.74%\n",
      "Epoch [20/30], Loss: 0.5784, Val Loss: 0.7882, Val Accuracy: 69.57%\n",
      "Epoch [21/30], Loss: 0.4867, Val Loss: 0.4658, Val Accuracy: 79.35%\n",
      "Epoch [22/30], Loss: 0.5085, Val Loss: 0.5267, Val Accuracy: 72.83%\n",
      "Epoch [23/30], Loss: 0.4382, Val Loss: 0.5936, Val Accuracy: 75.00%\n",
      "Epoch [24/30], Loss: 0.4491, Val Loss: 0.5867, Val Accuracy: 72.83%\n",
      "Epoch [25/30], Loss: 0.6080, Val Loss: 1.1666, Val Accuracy: 69.57%\n",
      "Epoch [26/30], Loss: 0.6249, Val Loss: 0.7690, Val Accuracy: 70.65%\n",
      "Epoch [27/30], Loss: 0.5938, Val Loss: 0.7078, Val Accuracy: 65.22%\n",
      "Epoch [28/30], Loss: 0.5225, Val Loss: 0.5249, Val Accuracy: 71.74%\n",
      "Epoch [29/30], Loss: 0.5078, Val Loss: 0.4631, Val Accuracy: 79.35%\n",
      "Epoch [30/30], Loss: 0.4744, Val Loss: 0.8674, Val Accuracy: 75.00%\n",
      "\n",
      "### Running Configuration 2 ###\n",
      "\n",
      "Epoch [1/50], Loss: 0.4263, Val Loss: 0.5323, Val Accuracy: 75.00%\n",
      "Epoch [2/50], Loss: 0.4161, Val Loss: 0.4795, Val Accuracy: 75.00%\n",
      "Epoch [3/50], Loss: 0.3861, Val Loss: 0.5251, Val Accuracy: 81.52%\n",
      "Epoch [4/50], Loss: 0.3790, Val Loss: 0.5345, Val Accuracy: 75.00%\n",
      "Epoch [5/50], Loss: 0.3709, Val Loss: 0.5055, Val Accuracy: 75.00%\n",
      "Epoch [6/50], Loss: 0.3797, Val Loss: 0.4744, Val Accuracy: 78.26%\n",
      "Epoch [7/50], Loss: 0.3660, Val Loss: 0.4814, Val Accuracy: 77.17%\n",
      "Epoch [8/50], Loss: 0.3609, Val Loss: 0.5251, Val Accuracy: 73.91%\n",
      "Epoch [9/50], Loss: 0.3306, Val Loss: 0.4872, Val Accuracy: 75.00%\n",
      "Epoch [10/50], Loss: 0.3248, Val Loss: 0.5600, Val Accuracy: 75.00%\n",
      "Epoch [11/50], Loss: 0.3298, Val Loss: 0.4842, Val Accuracy: 77.17%\n",
      "Epoch [12/50], Loss: 0.3202, Val Loss: 0.5731, Val Accuracy: 73.91%\n",
      "Epoch [13/50], Loss: 0.3280, Val Loss: 0.5051, Val Accuracy: 73.91%\n",
      "Epoch [14/50], Loss: 0.3318, Val Loss: 0.5025, Val Accuracy: 75.00%\n",
      "Epoch [15/50], Loss: 0.3437, Val Loss: 0.5389, Val Accuracy: 75.00%\n",
      "Epoch [16/50], Loss: 0.2954, Val Loss: 0.6161, Val Accuracy: 75.00%\n",
      "Epoch [17/50], Loss: 0.2842, Val Loss: 0.5743, Val Accuracy: 77.17%\n",
      "Epoch [18/50], Loss: 0.2834, Val Loss: 0.5552, Val Accuracy: 77.17%\n",
      "Epoch [19/50], Loss: 0.2698, Val Loss: 0.5747, Val Accuracy: 78.26%\n",
      "Epoch [20/50], Loss: 0.2858, Val Loss: 0.5948, Val Accuracy: 73.91%\n",
      "Epoch [21/50], Loss: 0.2642, Val Loss: 0.5704, Val Accuracy: 69.57%\n",
      "Epoch [22/50], Loss: 0.2593, Val Loss: 0.6786, Val Accuracy: 73.91%\n",
      "Epoch [23/50], Loss: 0.2579, Val Loss: 0.6992, Val Accuracy: 73.91%\n",
      "Epoch [24/50], Loss: 0.2518, Val Loss: 0.6573, Val Accuracy: 72.83%\n",
      "Epoch [25/50], Loss: 0.2563, Val Loss: 0.6722, Val Accuracy: 72.83%\n",
      "Epoch [26/50], Loss: 0.2303, Val Loss: 0.6577, Val Accuracy: 75.00%\n",
      "Epoch [27/50], Loss: 0.2093, Val Loss: 0.7753, Val Accuracy: 72.83%\n",
      "Epoch [28/50], Loss: 0.2251, Val Loss: 0.8353, Val Accuracy: 71.74%\n",
      "Epoch [29/50], Loss: 0.2200, Val Loss: 0.9006, Val Accuracy: 72.83%\n",
      "Epoch [30/50], Loss: 0.2172, Val Loss: 0.7774, Val Accuracy: 75.00%\n",
      "Epoch [31/50], Loss: 0.2203, Val Loss: 0.6769, Val Accuracy: 73.91%\n",
      "Epoch [32/50], Loss: 0.1962, Val Loss: 0.8227, Val Accuracy: 72.83%\n",
      "Epoch [33/50], Loss: 0.1837, Val Loss: 0.9036, Val Accuracy: 76.09%\n",
      "Epoch [34/50], Loss: 0.1741, Val Loss: 1.4467, Val Accuracy: 73.91%\n",
      "Epoch [35/50], Loss: 0.1854, Val Loss: 1.5263, Val Accuracy: 75.00%\n",
      "Epoch [36/50], Loss: 0.1930, Val Loss: 0.8419, Val Accuracy: 76.09%\n",
      "Epoch [37/50], Loss: 0.1697, Val Loss: 1.0576, Val Accuracy: 71.74%\n",
      "Epoch [38/50], Loss: 0.2177, Val Loss: 1.3189, Val Accuracy: 77.17%\n",
      "Epoch [39/50], Loss: 0.1957, Val Loss: 1.0395, Val Accuracy: 71.74%\n",
      "Epoch [40/50], Loss: 0.1634, Val Loss: 1.3416, Val Accuracy: 73.91%\n",
      "Epoch [41/50], Loss: 0.1498, Val Loss: 1.3202, Val Accuracy: 72.83%\n",
      "Epoch [42/50], Loss: 0.1331, Val Loss: 1.6381, Val Accuracy: 72.83%\n",
      "Epoch [43/50], Loss: 0.1468, Val Loss: 1.5799, Val Accuracy: 71.74%\n",
      "Epoch [44/50], Loss: 0.1400, Val Loss: 1.7809, Val Accuracy: 72.83%\n",
      "Epoch [45/50], Loss: 0.1291, Val Loss: 1.1894, Val Accuracy: 72.83%\n",
      "Epoch [46/50], Loss: 0.1531, Val Loss: 1.2288, Val Accuracy: 70.65%\n",
      "Epoch [47/50], Loss: 0.1272, Val Loss: 1.4819, Val Accuracy: 71.74%\n",
      "Epoch [48/50], Loss: 0.1085, Val Loss: 1.5200, Val Accuracy: 73.91%\n",
      "Epoch [49/50], Loss: 0.1049, Val Loss: 1.4453, Val Accuracy: 72.83%\n",
      "Epoch [50/50], Loss: 0.0903, Val Loss: 1.4801, Val Accuracy: 70.65%\n",
      "\n",
      "### Running Configuration 3 ###\n",
      "\n",
      "Epoch [1/30], Loss: 0.7860, Val Loss: 0.8534, Val Accuracy: 75.00%\n",
      "Epoch [2/30], Loss: 0.4296, Val Loss: 0.6206, Val Accuracy: 73.91%\n",
      "Epoch [3/30], Loss: 0.4240, Val Loss: 0.6235, Val Accuracy: 71.74%\n",
      "Epoch [4/30], Loss: 0.3988, Val Loss: 0.5589, Val Accuracy: 76.09%\n",
      "Epoch [5/30], Loss: 0.3746, Val Loss: 0.5736, Val Accuracy: 71.74%\n",
      "Epoch [6/30], Loss: 0.3754, Val Loss: 0.6042, Val Accuracy: 70.65%\n",
      "Epoch [7/30], Loss: 0.3849, Val Loss: 0.6170, Val Accuracy: 76.09%\n",
      "Epoch [8/30], Loss: 0.4052, Val Loss: 0.8011, Val Accuracy: 71.74%\n",
      "Epoch [9/30], Loss: 0.3878, Val Loss: 0.4820, Val Accuracy: 71.74%\n",
      "Epoch [10/30], Loss: 0.3617, Val Loss: 0.6261, Val Accuracy: 73.91%\n",
      "Epoch [11/30], Loss: 0.3640, Val Loss: 0.5844, Val Accuracy: 77.17%\n",
      "Epoch [12/30], Loss: 0.5228, Val Loss: 0.7787, Val Accuracy: 78.26%\n",
      "Epoch [13/30], Loss: 0.5037, Val Loss: 0.4881, Val Accuracy: 72.83%\n",
      "Epoch [14/30], Loss: 0.5106, Val Loss: 0.5658, Val Accuracy: 68.48%\n",
      "Epoch [15/30], Loss: 0.4632, Val Loss: 0.5552, Val Accuracy: 75.00%\n",
      "Epoch [16/30], Loss: 0.4108, Val Loss: 0.5208, Val Accuracy: 72.83%\n",
      "Epoch [17/30], Loss: 0.3369, Val Loss: 0.5762, Val Accuracy: 73.91%\n",
      "Epoch [18/30], Loss: 0.4207, Val Loss: 0.7757, Val Accuracy: 72.83%\n",
      "Epoch [19/30], Loss: 0.3908, Val Loss: 0.5402, Val Accuracy: 71.74%\n",
      "Epoch [20/30], Loss: 0.3239, Val Loss: 0.5553, Val Accuracy: 75.00%\n",
      "Epoch [21/30], Loss: 0.3211, Val Loss: 0.7427, Val Accuracy: 73.91%\n",
      "Epoch [22/30], Loss: 0.4289, Val Loss: 0.5529, Val Accuracy: 73.91%\n",
      "Epoch [23/30], Loss: 0.4156, Val Loss: 0.5656, Val Accuracy: 76.09%\n",
      "Epoch [24/30], Loss: 0.3956, Val Loss: 0.4643, Val Accuracy: 71.74%\n",
      "Epoch [25/30], Loss: 0.4369, Val Loss: 0.5163, Val Accuracy: 72.83%\n",
      "Epoch [26/30], Loss: 0.3665, Val Loss: 0.4911, Val Accuracy: 73.91%\n",
      "Epoch [27/30], Loss: 0.3322, Val Loss: 0.5762, Val Accuracy: 78.26%\n",
      "Epoch [28/30], Loss: 0.3244, Val Loss: 0.5493, Val Accuracy: 76.09%\n",
      "Epoch [29/30], Loss: 0.2909, Val Loss: 0.7093, Val Accuracy: 68.48%\n",
      "Epoch [30/30], Loss: 0.3466, Val Loss: 0.6830, Val Accuracy: 76.09%\n",
      "\n",
      "### Running Configuration 4 ###\n",
      "\n",
      "Epoch [1/40], Loss: 0.3970, Val Loss: 0.6900, Val Accuracy: 75.00%\n",
      "Epoch [2/40], Loss: 0.3377, Val Loss: 0.7735, Val Accuracy: 72.83%\n",
      "Epoch [3/40], Loss: 0.3012, Val Loss: 0.5676, Val Accuracy: 76.09%\n",
      "Epoch [4/40], Loss: 0.2877, Val Loss: 0.5850, Val Accuracy: 70.65%\n",
      "Epoch [5/40], Loss: 0.2704, Val Loss: 0.6618, Val Accuracy: 75.00%\n",
      "Epoch [6/40], Loss: 0.2736, Val Loss: 0.8210, Val Accuracy: 71.74%\n",
      "Epoch [7/40], Loss: 0.2627, Val Loss: 0.6812, Val Accuracy: 76.09%\n",
      "Epoch [8/40], Loss: 0.2799, Val Loss: 0.7376, Val Accuracy: 76.09%\n",
      "Epoch [9/40], Loss: 0.2486, Val Loss: 0.5934, Val Accuracy: 71.74%\n",
      "Epoch [10/40], Loss: 0.2401, Val Loss: 0.8200, Val Accuracy: 72.83%\n",
      "Epoch [11/40], Loss: 0.2459, Val Loss: 0.8082, Val Accuracy: 68.48%\n",
      "Epoch [12/40], Loss: 0.2425, Val Loss: 0.8454, Val Accuracy: 69.57%\n",
      "Epoch [13/40], Loss: 0.2571, Val Loss: 0.9287, Val Accuracy: 70.65%\n",
      "Epoch [14/40], Loss: 0.2361, Val Loss: 0.7896, Val Accuracy: 68.48%\n",
      "Epoch [15/40], Loss: 0.2303, Val Loss: 0.7316, Val Accuracy: 77.17%\n",
      "Epoch [16/40], Loss: 0.2213, Val Loss: 0.7680, Val Accuracy: 73.91%\n",
      "Epoch [17/40], Loss: 0.2067, Val Loss: 0.7419, Val Accuracy: 72.83%\n",
      "Epoch [18/40], Loss: 0.1733, Val Loss: 1.0603, Val Accuracy: 75.00%\n",
      "Epoch [19/40], Loss: 0.2193, Val Loss: 0.9286, Val Accuracy: 71.74%\n",
      "Epoch [20/40], Loss: 0.1980, Val Loss: 0.8331, Val Accuracy: 69.57%\n",
      "Epoch [21/40], Loss: 0.1708, Val Loss: 0.7481, Val Accuracy: 71.74%\n",
      "Epoch [22/40], Loss: 0.1686, Val Loss: 1.1089, Val Accuracy: 72.83%\n",
      "Epoch [23/40], Loss: 0.1748, Val Loss: 0.8958, Val Accuracy: 73.91%\n",
      "Epoch [24/40], Loss: 0.1606, Val Loss: 0.9922, Val Accuracy: 72.83%\n",
      "Epoch [25/40], Loss: 0.1480, Val Loss: 0.9807, Val Accuracy: 75.00%\n",
      "Epoch [26/40], Loss: 0.1450, Val Loss: 1.0507, Val Accuracy: 72.83%\n",
      "Epoch [27/40], Loss: 0.1574, Val Loss: 1.1021, Val Accuracy: 71.74%\n",
      "Epoch [28/40], Loss: 0.1720, Val Loss: 1.1455, Val Accuracy: 73.91%\n",
      "Epoch [29/40], Loss: 0.1401, Val Loss: 0.9785, Val Accuracy: 69.57%\n",
      "Epoch [30/40], Loss: 0.1203, Val Loss: 0.9703, Val Accuracy: 75.00%\n",
      "Epoch [31/40], Loss: 0.1893, Val Loss: 2.0236, Val Accuracy: 77.17%\n",
      "Epoch [32/40], Loss: 0.1674, Val Loss: 1.4644, Val Accuracy: 71.74%\n",
      "Epoch [33/40], Loss: 0.1447, Val Loss: 0.9461, Val Accuracy: 75.00%\n",
      "Epoch [34/40], Loss: 0.1302, Val Loss: 1.1885, Val Accuracy: 72.83%\n",
      "Epoch [35/40], Loss: 0.1318, Val Loss: 1.3113, Val Accuracy: 76.09%\n",
      "Epoch [36/40], Loss: 0.0958, Val Loss: 1.2731, Val Accuracy: 73.91%\n",
      "Epoch [37/40], Loss: 0.1004, Val Loss: 1.3116, Val Accuracy: 75.00%\n",
      "Epoch [38/40], Loss: 0.1241, Val Loss: 1.4676, Val Accuracy: 78.26%\n",
      "Epoch [39/40], Loss: 0.1652, Val Loss: 1.0892, Val Accuracy: 77.17%\n",
      "Epoch [40/40], Loss: 0.1438, Val Loss: 1.2226, Val Accuracy: 72.83%\n",
      "\n",
      "Final Results:\n",
      "   run  batch_size      lr     augmentation  epochs  final_val_loss  \\\n",
      "0    1          32  0.0010          default      30        0.867384   \n",
      "1    2          64  0.0001  horizontal_flip      50        1.480133   \n",
      "2    3          16  0.0005         rotation      30        0.683016   \n",
      "3    4          48  0.0002     color_jitter      40        1.222641   \n",
      "\n",
      "   final_val_accuracy  \n",
      "0           75.000000  \n",
      "1           70.652174  \n",
      "2           76.086957  \n",
      "3           72.826087  \n"
     ]
    }
   ],
   "source": [
    "# Define runs with different parameters\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "runs = [\n",
    "    {\"batch_size\": 32, \"lr\": 0.001, \"augmentation\": \"default\", \"epochs\": 30, \"step_size\": 5},\n",
    "    {\"batch_size\": 64, \"lr\": 0.0001, \"augmentation\": \"horizontal_flip\", \"epochs\": 50, \"step_size\": 10},\n",
    "    {\"batch_size\": 16, \"lr\": 0.0005, \"augmentation\": \"rotation\", \"epochs\": 30, \"step_size\": 5},\n",
    "    {\"batch_size\": 48, \"lr\": 0.0002, \"augmentation\": \"color_jitter\", \"epochs\": 40, \"step_size\": 8},\n",
    "]\n",
    "\n",
    "# Define augmentation options\n",
    "def get_transforms(augmentation_type):\n",
    "    if augmentation_type == \"default\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "    elif augmentation_type == \"horizontal_flip\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "    elif augmentation_type == \"rotation\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "    elif augmentation_type == \"color_jitter\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "# Training loop for dynamic runs\n",
    "results = []\n",
    "\n",
    "# create model and adapt it to coral Dataset\n",
    "model = models.vgg16_bn(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "# move model to the gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    print(f\"\\n### Running Configuration {i + 1} ###\\n\")\n",
    "    \n",
    "    # Set up the dataset and dataloaders\n",
    "    transform = get_transforms(run[\"augmentation\"])\n",
    "    train_dataset = CoralDataset(train_paths, train_labels, transform=transform)\n",
    "    val_dataset = CoralDataset(val_paths, val_labels, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=run[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=run[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=run[\"lr\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=run[\"step_size\"], gamma=0.1)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(run[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{run['epochs']}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Log results for this run\n",
    "    results.append({\n",
    "        \"run\": i + 1,\n",
    "        \"batch_size\": run[\"batch_size\"],\n",
    "        \"lr\": run[\"lr\"],\n",
    "        \"augmentation\": run[\"augmentation\"],\n",
    "        \"epochs\": run[\"epochs\"],\n",
    "        \"final_val_loss\": val_loss / len(val_loader),\n",
    "        \"final_val_accuracy\": val_accuracy,\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
